import os, glob, re
from datetime import datetime
import pytest

# from osgeo import gdal
# import numpy as np

# # from urllib.request import urlretrieve
# from netCDF4 import Dataset

from cumulus_geoproc.processors import geo_proc
from cumulus_geoproc.utils import cgdal

from config import FIXTURE_INFO


# Prevent gdal from creating *.aux.xml stat files
os.environ["GDAL_PAM_ENABLED"] = "NO"

# """
# print(ncds.variables)

# {'Total_precipitation': <class 'netCDF4._netCDF4.Variable'>
# float32 Total_precipitation(time, y, x)
#     units: kg/m^2
#     standard_name: precipitation_amount
#     long_name: 01 hr Precip
#     cell_methods: time: sum
#     missing_value: -9999.0
#     grid_mapping: Polar_Stereographic
#     coordinates: time y x 
#     udunits: millimeter
#     uiname: 01 hr precip estimate
#     valid_range: [   0. 1000.]
#     _FillValue: -9999.0
#     _n3D: 0
#     levels: SFC
# """


class ProcessorResult:
    """A class to hold relevant information about an acquirable and productfiles generated by geo_proc()"""

    def __init__(self, processor, filepath, reasonable_min, reasonable_max):
        self.processor = processor
        self.infile = os.path.join("/src/tests/integration/fixtures", filepath)
        self.output_directory = f"/output/{self.processor}"
        self.reasonable_min = reasonable_min
        self.reasonable_max = reasonable_max
        self.result = self.process()  # Run geoprocessing

    def process(self):
        try:
            os.makedirs(self.output_directory, exist_ok=True)
            return geo_proc(plugin=self.processor, src=self.infile, dst=self.output_directory)
        except:
            return []
    @property
    def min(self):
        # TODO: Return maximum gridcell value in all grids returned by process() to be used in integration tests
        # Can probably call gdalinfo -stats (or gdal python binding equivalent) to get min,max.
        pass
    
    @property
    def max(self):
        # TODO: Return minimum gridcell value in all grids returned by process() to be used in integration tests
        # Can probably call gdalinfo -stats (or gdal python binding equivalent) to get min,max.
        pass


# scope="module" results in processing being computed once, reused in subsequent tests
# see https://docs.pytest.org/en/6.2.x/fixture.html#scope-sharing-fixtures-across-classes-modules-packages-or-session
@pytest.fixture(scope="module")
def processed():
    return [ProcessorResult(*entry) for entry in FIXTURE_INFO]


###############################################################################################################
# TEST CASES
###############################################################################################################

def test_infile_exists(processed) -> None:
    for p in processed:
        assert os.path.isfile(p.infile), "Specified test file does not exist"


def test_productfile_at_least_one(processed) -> None:
    for p in processed:
        assert len(p.result) > 0, "Processor did not produce at least one productfile"


def test_productfile_file_exists_on_disk(processed) -> None:
    for p in processed:
        for r in p.result:
            file = r["file"]
            assert os.path.isfile(file), f"Productfile does not exist on disk: {file}"


def test_productfile_version_is_none(processed) -> None:
    # Version should be None, or a version that is not the default version
    for p in processed:
        for r in p.result:
            assert r["version"] is None or not r["version"].startswith("1111-11-11T11:11:11"), """
            Version explicitly set to default version in database.
            Recommend setting version = None and letting the database handle this
            """


def test_productfile_filename_has_datetime(processed) -> None:
    for p in processed:
        for r in p.result:
            # NOTE: Optional _ for product cnrfc-qpe-06h; source file uses YYYYMMDD_HHHH
            match = re.search(r"\d{4}\d{2}\d{2}_?\d{2}", os.path.basename(r["file"]))
            assert match is not None and datetime.strptime(
                match.group().replace("_", ""), "%Y%M%d%H"
            ), f"output filename does not contain valid datetime string: {r['file']}"


def test_productfile_is_valid_cog(processed) -> None:
    for p in processed:
        for r in p.result:
            file = r["file"]
            assert cgdal.validate_cog("-q", file) == 0, f"failed validate_cog: {file}"


def test_stats_max_reasonable(processed) -> None:
    # for p in processed:
    #     if p.reasonable_max is not None:
    #         assert p.reasonable_max < p.max, "maximum value in grid is unreasonably high"
    pass


def test_stats_min_reasonable(processed) -> None:
    # for p in processed:
    #     if p.reasonable_min is not None:
    #         assert p.reasonable_min < p.min, "minimum value in grid is unreasonably low"
    pass

