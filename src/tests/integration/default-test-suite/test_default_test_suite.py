import os, glob, re
from datetime import datetime
import pytest

# from osgeo import gdal
# import numpy as np

# # from urllib.request import urlretrieve
# from netCDF4 import Dataset

from cumulus_geoproc.processors import geo_proc
from cumulus_geoproc.utils import cgdal

from config import FIXTURE_INFO, DATE_FORMATS


# Prevent gdal from creating *.aux.xml stat files
os.environ["GDAL_PAM_ENABLED"] = "NO"


class ProcessorResult:
    """A class to hold relevant information about an acquirable and productfiles generated by geo_proc()"""

    def __init__(self, processor, filepath, reasonable_min, reasonable_max):
        self.processor = processor
        self.infile = os.path.join("/src/tests/integration/fixtures", filepath)
        self.output_directory = f"/output/{self.processor}"
        self.reasonable_min = reasonable_min
        self.reasonable_max = reasonable_max
        self.result = self.process()  # Run geoprocessing

    def process(self):
        try:
            os.makedirs(self.output_directory, exist_ok=True)
            return geo_proc(
                plugin=self.processor, src=self.infile, dst=self.output_directory
            )
        except:
            return []

    @property
    def min(self):
        # TODO: Return maximum gridcell value in all grids returned by process() to be used in integration tests
        # Can probably call gdalinfo -stats (or gdal python binding equivalent) to get min,max.
        pass

    @property
    def max(self):
        # TODO: Return minimum gridcell value in all grids returned by process() to be used in integration tests
        # Can probably call gdalinfo -stats (or gdal python binding equivalent) to get min,max.
        pass


# scope="module" results in processing being computed once, reused in subsequent tests
# see https://docs.pytest.org/en/6.2.x/fixture.html#scope-sharing-fixtures-across-classes-modules-packages-or-session
@pytest.fixture(scope="module")
def processed():
    return [ProcessorResult(*entry) for entry in FIXTURE_INFO]


###############################################################################################################
# TEST CASES
###############################################################################################################


def test_infile_exists(processed) -> None:
    for p in processed:
        assert os.path.isfile(p.infile), "Specified test file does not exist"


def test_productfile_at_least_one(processed) -> None:
    for p in processed:
        assert len(p.result) > 0, "Processor did not produce at least one productfile"


def test_productfile_file_exists_on_disk(processed) -> None:
    for p in processed:
        for r in p.result:
            file = r["file"]
            assert os.path.isfile(file), f"Productfile does not exist on disk: {file}"


def test_productfile_version_is_none(processed) -> None:
    # Version should be None, or a version that is not the default version
    for p in processed:
        for r in p.result:
            assert r["version"] is None or not r["version"].startswith(
                "1111-11-11T11:11:11"
            ), """
            Version explicitly set to default version in database.
            Recommend setting version = None and letting the database handle this
            """


def test_productfile_filename_has_datetime(processed) -> None:
    for p in processed:
        for r in p.result:
            match = None
            for fmt, regex in DATE_FORMATS:
                try:
                    match = re.search(regex, os.path.basename(r["file"]))
                    if match.group():
                        assert datetime.strptime(
                            match.group(), fmt
                        ), f"output filename does not contain valid datetime string: {r['file']}"
                        break
                except:
                    pass

            assert (
                match is not None
            ), f"output filename does not contain datetime string: {r['file']}"


def test_productfile_is_valid_cog(processed) -> None:
    for p in processed:
        for r in p.result:
            file = r["file"]
            assert cgdal.validate_cog("-q", file) == 0, f"failed validate_cog: {file}"


def test_stats_max_reasonable(processed) -> None:
    # for p in processed:
    #     if p.reasonable_max is not None:
    #         assert p.reasonable_max < p.max, "maximum value in grid is unreasonably high"
    pass


def test_stats_min_reasonable(processed) -> None:
    # for p in processed:
    #     if p.reasonable_min is not None:
    #         assert p.reasonable_min < p.min, "minimum value in grid is unreasonably low"
    pass
